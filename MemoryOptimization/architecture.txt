CPU Caches:




Virtual Memory:




Cache Bypass:




Optimizing L1d:




Optimizing L1i:




Prefetching:
Used to hide Main Memory Latency
  Hardware Prefetching:
    Process Agnostic
    Hardware Prefetcher is per L1 / L2 / L3 Cache
    Uses streams to track cache line access patterns
    It can recognize stride patterns
    Very effective in sequential access patterns
    Does not work accross Page boundaries, and random access

  Software Prefetcher:
    __builtin_prefetch (const void *addr, rw, locality)
    rw = 0 : Acquire in Exclusive / Shared state
    rw = 1 : Acquire in Exclusive / Shared state, then write to it
    locality = 0 (Non temporal) / 1 (>=L1) / 2(>=L2) / 3 (>= L3)
              

Multithreaded Optimizations:






















